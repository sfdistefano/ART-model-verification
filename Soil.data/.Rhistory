summ.UTGas.cover.match <- summ.UTGas.cover[summ.UTGas.cover$SiteName %in% summ.ART.cover$SiteName,]
# subsetting only the cover for reference sites
summ.UTGas.ref.cover <- summ.UTGas.cover.match[grep("Reference|Road Ref", summ.UTGas.cover.match$PlotID),]
# all cover data for reference and ART plots in one df
summ.cover <- rbind.fill(summ.ART.cover, summ.UTGas.ref.cover)
# setting all NAs to 0 in preparation for similarity calculations
summ.cover[is.na(summ.cover)] <- 0
summ.cover$SiteName <- gsub(pattern = "CATH FED 30 01 Well Pad",
replacement = "Cath Fed 30 01 Well Pad",
x = summ.cover$SiteName)
#### BRAY-CURTIS ####
# each list component, is all the plots related to one reclamation area # used for bray-curtis
summ.cover.split <- split(x = summ.cover, f = summ.cover$SiteName)
# removing non-numeric columns that don't have numeric information otherwise you'll get an error message when trying to calculate vegdist()
sim.cover.filter <- lapply(summ.cover.split, FUN = function(x){x[, c(5:130)]})
# converting first column into rownames, this makes it possible to run the sim index which requires all numeric values in matrix
sim.cover.filter <- lapply(sim.cover.filter, function(x){ row.names(x)<-as.character(x$PlotID); x})
# removed the first column of PlotID (they are now rownames)
sim.cover.filter <- lapply(sim.cover.filter, FUN = function(x){x[, c(2:126)]})
# calculating the difference between plots of the same reclamation using bray-curtis # 0 = completely similar, 1 = completely dissimilar
sim.analysis <- lapply(sim.cover.filter, function(x){vegdist(x, method =  "bray")})
# converts sim index output ("dist")into usable dataframe output
sim.df <- lapply(sim.analysis, function(x){as.data.frame(as.matrix(x))})
# converting rownames into first column
sim.df <- lapply(sim.df, function(x){tibble::rownames_to_column(x, "Plot1")})
# transforming to a long format, where there's a distance value between 2 plots in each row
sim.gathered <- lapply(sim.df, function(x){melt(x, id.vars = "Plot1", variable.name = "Plot2", value.name = "distance")})
# selecting only rows that pertain to reference similarity
sim.ref.values <- lapply(sim.gathered, function(x){x[grep("Reference|Road Ref", x$Plot1),]})
# combines all elements of list into one dataframe
similarity <- ldply(sim.gathered, data.frame)
similarity$bray.sim <- 1 - similarity$distance
similarity.ref <- similarity[!grepl("Reference|Road Ref", similarity$Plot2),]
similarity.ref <- similarity.ref[grepl("Reference|Road Ref", similarity.ref$Plot1),]
write.csv(similarity.ref, "bray.csv")
#### SIMPSON ####
# removing non-numeric columns that don't have numeric information otherwise you'll get an error message when trying to calculate vegdist()
simpson.filter <- summ.cover[, c(5:130)]
# converting first column into rownames, this makes it possible to run the sim index which requires all numeric values in matrix
row.names(simpson.filter)<-as.character(simpson.filter$PlotID)
# removed the first column of PlotID (they are now rownames)
simpson.filter <- simpson.filter[, c(2:126)]
# calculate simpson diversity indice for each plot
simpson.results <- diversity(simpson.filter, index = "simpson")
# converts results into usable dataframe
simpson.results.df <- as.data.frame(as.matrix(simpson.results))
# converts rownames to column "PlotID"
simpson.results.df <- tibble::rownames_to_column(simpson.results.df, "PlotID")
# rename second column
colnames(simpson.results.df)[2] <- "simpson"
# adding SiteName so that they can be split later for comparison
simpson <- merge(x = simpson.results.df, y = summ.cover, by = "PlotID", all.x = T)[,c("SiteName","PlotID", "simpson")]
write.csv(simpson, "simpson.results.csv")
# splitting plots based on shared "SiteName" aka they share the same reclamation
simpson.split <- split(x = simpson, f = simpson$SiteName)
#### SHANNON-WIENER ####
# removing non-numeric columns that don't have numeric information otherwise you'll get an error message when trying to calculate vegdist()
shannon.filter <- summ.cover[, c(5:130)]
# converting first column into rownames, this makes it possible to run the sim index which requires all numeric values in matrix
row.names(shannon.filter)<-as.character(shannon.filter$PlotID)
# removed the first column of PlotID (they are now rownames)
shannon.filter <- shannon.filter[, c(2:126)]
# calculate simpson diversity indice for each plot
shannon.results <- diversity(shannon.filter, index = "shannon")
# converts results into usable dataframe
shannon.results.df <- as.data.frame(as.matrix(shannon.results))
# converts rownames to column "PlotID"
shannon.results.df <- tibble::rownames_to_column(shannon.results.df, "PlotID")
# rename second column
colnames(shannon.results.df)[2] <- "shannon"
# adding SiteName so that they can be split later for comparison
shannon <- merge(x = shannon.results.df, y = summ.cover, by = "PlotID", all.x = T)[,c("SiteName","PlotID", "shannon")]
write.csv(shannon, "shannon.results.csv")
#### FINAL DIVERSITY RESULTS ####
diversity <- merge(x = shannon, y = simpson, by = "PlotID")[,c("SiteName.x","PlotID", "simpson", "shannon")]
write.csv(diversity, "diversity.results.csv")
setwd("C:/Users/sfper/Dropbox/DiStefano_WRFO_project/GIS_data")
# reading in all UT Gas Corp reference sites
ref.sites <- as.data.frame(readOGR("C:/Users/sfper/Dropbox/DiStefano_WRFO_project/GIS_data/WRFO_reference_UtahGas_plot_locations.shp"))
# filtering out reference sites that won't be used
similarity.ref <- read.csv("C:/Users/sfper/Dropbox/DiStefano_WRFO_project/bray.csv")
ART.ref.sites <- ref.sites %>% filter(PlotID %in% similarity.ref$Plot1)
# adding the reference site that had blank LPI data so that I can create a complete shapefile # should be 11 reference plots
# ART.ref.sites <- rbind(ART.ref.sites, ref.sites[ref.sites$PlotID == "SDC 7326 Reference",])
# selects the only columns necessary for a shapefile
ART.ref.sites <- ART.ref.sites[, c("PlotID", "Longitd", "Latitud")]
#creates spatial points data frame of reference sites that will be compared to
ART.reference.spdf <- sp::SpatialPointsDataFrame(coords = dplyr::select(ART.ref.sites, Longitd, Latitud),
data = ART.ref.sites,
proj4string = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"))
# transforms spdf to shapefile
rgdal::writeOGR(obj = ART.reference.spdf,
dsn = "C:/Users/sfper/Dropbox/DiStefano_WRFO_project/GIS_data",
layer = "ART.reference",
driver = "ESRI Shapefile",
overwrite_layer = TRUE)
# read in calculated similarity values from ART model
ART.values <- read.csv("C:/Users/sfper/Dropbox/DiStefano_WRFO_project/ART.plots_info.csv")
# standardizing names so that merge can go smoothly
ART.values$PlotID <- gsub(pattern = "Road", x = ART.values$PlotID, replacement = "Rd")
ART.values$PlotID <- gsub(pattern = "CATH FED 30 01", replacement = "Cath Fed 30 01", x = ART.values$PlotID)
ART.values$PlotID <- gsub(pattern = "DTU 1058 Well Pad FR", replacement = "DTU 1058", x = ART.values$PlotID)
ART.values$PlotID <- gsub(pattern = "Cities Fed 07 31 FR Well Pad", replacement = "Cities Fed 07 31 FR", x = ART.values$PlotID)
ART.values$PlotID <- gsub(pattern = "PK MTN 9016 FR", replacement = "Pk Mtn 9016", x = ART.values$PlotID)
colnames(ART.values)[6] <- "ART.value"
# sets up for comparison of a plot's ART value to it's bray-curtis similarity value
similarity_ref.ART <- merge(x = similarity.ref, y = ART.values,
by.x = "Plot2", by.y = "PlotID")[, c("Plot1", "Plot2", "bray.sim", "ART.value")]
# removes rows that aren't valid comparisons (not correct ref site to compare to)
similarity_ref.ART <- similarity_ref.ART[!(similarity_ref.ART$Plot1 == "Cath Fed P 35 3 101Road Ref" &
similarity_ref.ART$Plot2 == "Cath Fed P 35 3 101 FR Plot 1"),]
similarity_ref.ART <- similarity_ref.ART[!(similarity_ref.ART$Plot1 == "Cath Fed P 35 3 101Road Ref" &
similarity_ref.ART$Plot2 == "Cath Fed P 35 3 101 FR Plot 2"),]
similarity_ref.ART <- similarity_ref.ART[!(similarity_ref.ART$Plot1 == "Cath Fed P 35 3 101 Reference" &
similarity_ref.ART$Plot2 == "Cath Fed P 35 3 101 Rd Plot 1"),]
similarity_ref.ART <- similarity_ref.ART[!(similarity_ref.ART$Plot1 == "Cath Fed P 35 3 101 Reference" &
similarity_ref.ART$Plot2 == "Cath Fed P 35 3 101 Rd Plot 2"),]
# creates master comparison df of a plot's ART value to its bray-curtis, simpson, and shannon values
diversity <- read.csv("C:/Users/sfper/Dropbox/DiStefano_WRFO_project/diversity.results.csv")
ART.analysis <- merge(x = similarity_ref.ART, y = diversity,
by.x = "Plot2", by.y = "PlotID", all.x = T)[,c("SiteName.x", "Plot1", "Plot2", "bray.sim", "simpson", "shannon", "ART.value")]
colnames(ART.analysis)[1] <- "SiteName"
ART.analysis$SiteName <- as.character(ART.analysis$SiteName) # character is easier to work with in the following code
# extract reference site rows
ref.diversity <- diversity[grep("Reference|Road Ref", diversity$PlotID),]
colnames(ref.diversity) <- c("SiteName", "RefPlot", "ref.simp", "ref.shann")
# extract ART plot rows
plot.diversity <- diversity[!grepl("Reference|Road Ref", diversity$PlotID),]
colnames(plot.diversity) <- c("SiteName", "ARTPlot", "ART.simp", "ART.shann")
# sets up for comparison of a plot's diversity to its reference
diversity.wide <- merge(ref.diversity, plot.diversity, by = "SiteName", all.x = T)
#### MASTER ANALYSIS DATAFRAME ####
ART.info <- read.csv("C:/Users/sfper/Dropbox/DiStefano_WRFO_project/RefSite_info/UT_GasCorp_reclamation_sites_info.csv")
# standardizing names so it can be successfully merged later
ART.info$SiteNam <- gsub(pattern = "CATH FED 30 01", replacement = "Cath Fed 30 01", x = ART.info$SiteNam)
ART.info <- ART.info %>% mutate(SiteNam = ifelse(PlotID == "Cath Fed P 35 3 101 Road" & SiteNam == "Cath Fed P 35 3 101 Well Pad", "Cath Fed P 35 3 101 Road", SiteNam))
ART.analysis <- ART.analysis %>% mutate(SiteName = ifelse(Plot1 == "Cath Fed P 35 3 101Road Ref" & SiteName == "Cath Fed P 35 3 101 Well Pad", "Cath Fed P 35 3 101 Road", SiteName))
# renaming site names where road plots had their own reference site
ART.info <- ART.info %>% mutate(SiteNam = ifelse(PlotID == "A-30-3-101S Federal Road" & SiteNam == "A-30-3-101S Federal Well Pad", "A-30-3-101S Federal Road", SiteNam))
ART.analysis <- ART.analysis %>% mutate(SiteName = ifelse(Plot2 == "A-30-3-101S Rd Plot 1" & SiteName == "A-30-3-101S Federal Reference", "A-30-3-101S Federal Road", SiteName))
ART.analysis <- ART.analysis %>% mutate(SiteName = ifelse(Plot2 == "A-30-3-101S Rd Plot 2" & SiteName == "A-30-3-101S Federal Reference", "A-30-3-101S Federal Road", SiteName))
ART.info <- ART.info %>% mutate(SiteNam = ifelse(PlotID == "CATH FED 30 01 Road" & SiteNam == "Cath Fed 30 01 Well Pad", "Cath Fed 30 01 Road", SiteNam))
ART.analysis <- ART.analysis %>% mutate(SiteName = ifelse(Plot2 == "Cath Fed 30 01 Rd Plot 1" & SiteName == "Cath Fed 30 01 Well Pad", "Cath Fed 30 01 Road", SiteName))
ART.analysis <- ART.analysis %>% mutate(SiteName = ifelse(Plot2 == "Cath Fed 30 01 Rd Plot 2" & SiteName == "Cath Fed 30 01 Well Pad", "Cath Fed 30 01 Road", SiteName))
# simpson and shannon values are for the ART plots, not the reference sites
comparisons <- merge(x = ART.analysis, y = ART.info, by.x = "SiteName", by.y = "SiteNam", all.x = T)[,c("SiteName", "Plot1", "Plot2", "bray.sim", "simpson", "shannon", "Abandon_date", "ART.value")]
# adding date of well pad abandonment
comparisons$Abandon_date <- as.Date(comparisons$Abandon_date)
# separating year from date
comparisons$abandon_year <- format(as.Date(comparisons$Abandon_date, format = "%Y%m%d"), "%Y")
# converting to character to make it easier to work with
comparisons$Plot1 <- as.character(comparisons$Plot1)
comparisons$Plot2 <- as.character(comparisons$Plot2)
ggplotRegression <- function(fit){
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red", se = F) +
labs(title = paste("R2 = ",signif(summary(fit)$r.squared, 2),
"Intercept =",signif(fit$coef[[1]],2 ),
" Regression Coefficient =",signif(fit$coef[[2]], 2),
" p-value =",signif(summary(fit)$coef[2,4], 2)))
}
comparisons <- read.csv("C:/Users/sfper/Dropbox/DiStefano_WRFO_project/comparison.csv")
View(comparisons)
library(raster)
library(rgdal)
library(plyr)
library(qdapRegex)
library(psych)
setwd("C:/Users/seaperry/Dropbox/DiStefano_WRFO_project/GIS_data")
# pulling raster that has the slope values calculated from DEM in QGIS
slope <- raster("TerrainAnalysis/Slope08142017.tif")
# reading in the plot locations
ref.sites <- readOGR("WRFO_reference_UtahGas_plot_locations.shp")
rec.sites <- readOGR("rec.sites.visit.shp")
ART.plots <- readOGR("final_ART.plots.shp")
# extracting slope values
rec.slope <- as.data.frame(extract(slope, rec.sites, method = "simple"))
rec.slope$PlotID <- rec.sites$PlotID
rec.slope$SiteID <- rec.sites$SiteID
colnames(rec.slope)[1] <- "slope"
# cleaning up SiteID column in preparation for merge()
rec.slope$SiteID <- gsub(pattern = "Road|FR|Well Pad|Federal|L19 2101|[()]|D25 1103",
replacement = "",
x = rec.slope$SiteID)
rec.slope$SiteID <- rm_white(rec.slope$SiteID)
# cleaning up SiteID column in preparation for merge()
ref.slope <- as.data.frame(extract(slope, ref.sites, method = "simple"))
ref.slope$PlotID <- ref.sites$PlotID
ref.slope$SiteID <- ref.sites$SiteID
colnames(ref.slope)[1] <- "slope"
ref.slope$SiteID <- gsub(pattern = "Road|FR|Well Pad|Federal|L19 2101|[()]|D25 1103",
replacement = "",
x = ref.slope$SiteID)
ref.slope$SiteID <- rm_white(ref.slope$SiteID)
# cleaning up SiteID column in preparation for merge()
ART.slope <- as.data.frame(extract(slope, ART.plots, method = "simple"))
ART.slope$PlotID <- ART.plots$PlotID
ART.slope$SiteID <- gsub(pattern = "Plot 1|Plot 2|Road|FR|Well Pad|Federal",
replacement = "",
x =ART.slope$PlotID)
ART.slope$SiteID <- rm_white(ART.slope$SiteID)
# creates long dataframe
total.slope <- rbind(ref.slope, rec.slope, ART.slope)
# creates wide dataframe
slope.wide <- merge(rec.slope, ref.slope, by = "SiteID")
# resulting df has the slopes of each ART plot with their corresponding rec and ref site
# there are duplicates of rec and ref sites since ART plots share them
total.slope.wide <- merge(slope.wide, ART.slope, by = "SiteID")
# calculating how many are above 5 degree slope (8.75%) b/c it's a parameter for PSC criteria
total.slope.wide$ref.slope.greater5 <- total.slope.wide$slope.ref >.0875
total.slope.wide$ART.slope.greater5 <- total.slope.wide$slope.ART >.0875
total.slope.wide[total.slope.wide$ART.slope.greater5 == "FALSE", total.slope.wide$ref.lf] <- "middle slope"
slope.road.rec <- total.slope.wide[grepl(x = total.slope.wide$reclamation, pattern = "Road"), ]
slope.road <- slope.road.rec[grepl(x = slope.road.rec$ART.plot, pattern = "Road"),]
slope.road <- slope.road.rec[grepl(x = slope.road.rec$Reference, pattern = "Road"),]
slope.road <- slope.road[!grepl(x = slope.road$reference, pattern = "Cath Fed P 35 3 101 Reference"),]
slope.WP <- total.slope.wide[!grepl(x = total.slope.wide$reclamation, pattern = "Road"),]
slope.WP <- slope.WP[!grepl(x = slope.WP$ART.plot, pattern = "Road"),]
slope.total <- rbind(slope.WP, slope.road)
lf.match <- as.matrix(table(slope.total[9:10]))
lf.kappa <- cohen.kappa(lf.match)
slope <- raster("TerrainAnalysis/Slope08142017.tif")
# reading in the plot locations
ref.sites <- readOGR("WRFO_reference_UtahGas_plot_locations.shp")
rec.sites <- readOGR("rec.sites.visit.shp")
ART.plots <- readOGR("final_ART.plots.shp")
# extracting slope values
rec.slope <- as.data.frame(extract(slope, rec.sites, method = "simple"))
rec.slope$PlotID <- rec.sites$PlotID
rec.slope$SiteID <- rec.sites$SiteID
colnames(rec.slope)[1] <- "slope"
rec.slope$SiteID <- gsub(pattern = "Road|FR|Well Pad|Federal|L19 2101|[()]|D25 1103",
replacement = "",
x = rec.slope$SiteID)
rec.slope$SiteID <- rm_white(rec.slope$SiteID)
ref.slope <- as.data.frame(extract(slope, ref.sites, method = "simple"))
ref.slope$PlotID <- ref.sites$PlotID
ref.slope$SiteID <- ref.sites$SiteID
colnames(ref.slope)[1] <- "slope"
ref.slope$SiteID <- gsub(pattern = "Road|FR|Well Pad|Federal|L19 2101|[()]|D25 1103",
replacement = "",
x = ref.slope$SiteID)
ref.slope$SiteID <- rm_white(ref.slope$SiteID)
ART.slope <- as.data.frame(extract(slope, ART.plots, method = "simple"))
ART.slope$PlotID <- ART.plots$PlotID
ART.slope$SiteID <- gsub(pattern = "Plot 1|Plot 2|Road|FR|Well Pad|Federal",
replacement = "",
x =ART.slope$PlotID)
ART.slope$SiteID <- rm_white(ART.slope$SiteID)
# creates long dataframe
total.slope <- rbind(ref.slope, rec.slope, ART.slope)
# creates wide dataframe
slope.wide <- merge(rec.slope, ref.slope, by = "SiteID")
ART.slope <- as.data.frame(extract(slope, ART.plots, method = "simple"))
ART.slope$PlotID <- ART.plots$PlotID
ART.slope$SiteID <- gsub(pattern = "Plot 1|Plot 2|Road|FR|Well Pad|Federal",
replacement = "",
x =ART.slope$PlotID)
ART.slope$SiteID <- rm_white(ART.slope$SiteID)
# creates long dataframe
total.slope <- rbind(ref.slope, rec.slope, ART.slope)
View(ref.slope)
head(ref.slope, 3)
head(rec.slope,3)
head(ART.slope,3)
colnames(ref.slope)[1] <- "slope"
ref.slope$SiteID <- gsub(pattern = "Road|FR|Well Pad|Federal|L19 2101|[()]|D25 1103",
replacement = "",
x = ref.slope$SiteID)
ref.slope$SiteID <- rm_white(ref.slope$SiteID)
# cleaning up SiteID column in preparation for merge()
ART.slope <- as.data.frame(extract(slope, ART.plots, method = "simple"))
ART.slope$PlotID <- ART.plots$PlotID
ART.slope$SiteID <- gsub(pattern = "Plot 1|Plot 2|Road|FR|Well Pad|Federal",
replacement = "",
x =ART.slope$PlotID)
ART.slope$SiteID <- rm_white(ART.slope$SiteID)
colnames(ART.slope)[1] <- "slope"
ART.slope$SiteID <- gsub(pattern = "Plot 1|Plot 2|Road|FR|Well Pad|Federal",
replacement = "",
x =ART.slope$PlotID)
ART.slope$SiteID <- rm_white(ART.slope$SiteID)
# creates long dataframe
total.slope <- rbind(ref.slope, rec.slope, ART.slope)
# creates wide dataframe
slope.wide <- merge(rec.slope, ref.slope, by = "SiteID")
# resulting df has the slopes of each ART plot with their corresponding rec and ref site
# there are duplicates of rec and ref sites since ART plots share them
total.slope.wide <- merge(slope.wide, ART.slope, by = "SiteID")
# calculating how many are above 5 degree slope (8.75%) b/c it's a parameter for PSC criteria
total.slope.wide$ref.slope.greater5 <- total.slope.wide$slope.ref >.0875
total.slope.wide$ART.slope.greater5 <- total.slope.wide$slope.ART >.0875
total.slope.wide[total.slope.wide$ART.slope.greater5 == "FALSE", total.slope.wide$ref.lf] <- "middle slope"
slope.road.rec <- total.slope.wide[grepl(x = total.slope.wide$reclamation, pattern = "Road"), ]
slope.road <- slope.road.rec[grepl(x = slope.road.rec$ART.plot, pattern = "Road"),]
slope.road <- slope.road.rec[grepl(x = slope.road.rec$Reference, pattern = "Road"),]
slope.road <- slope.road[!grepl(x = slope.road$reference, pattern = "Cath Fed P 35 3 101 Reference"),]
slope.WP <- total.slope.wide[!grepl(x = total.slope.wide$reclamation, pattern = "Road"),]
slope.WP <- slope.WP[!grepl(x = slope.WP$ART.plot, pattern = "Road"),]
slope.total <- rbind(slope.WP, slope.road)
lf.match <- as.matrix(table(slope.total[9:10]))
head(slope.total,3)
head(slope.WP)
View(total.slope.wide)
head(total.slope.wide)
# calculating how many are above 5 degree slope (8.75%) b/c it's a parameter for PSC criteria
total.slope.wide$ref.slope.greater5 <- total.slope.wide$slope.ref >.0875
colnames(total.slope.wide) <- c("SiteID", "rec.slope", "reclamation",
"ref.slope", "reference", "ART.slope", "ART.plot")
# calculating how many are above 5 degree slope (8.75%) b/c it's a parameter for PSC criteria
total.slope.wide$ref.slope.greater5 <- total.slope.wide$slope.ref >.0875
colnames(total.slope.wide) <- c("SiteID", "slope.rec", "reclamation",
"slope.ref", "reference", "slope.ART", "ART.plot")
# calculating how many are above 5 degree slope (8.75%) b/c it's a parameter for PSC criteria
total.slope.wide$ref.slope.greater5 <- total.slope.wide$slope.ref >.0875
total.slope.wide$ART.slope.greater5 <- total.slope.wide$slope.ART >.0875
total.slope.wide[total.slope.wide$ART.slope.greater5 == "FALSE", total.slope.wide$ref.lf] <- "middle slope"
slope.road.rec <- total.slope.wide[grepl(x = total.slope.wide$reclamation, pattern = "Road"), ]
slope.road <- slope.road.rec[grepl(x = slope.road.rec$ART.plot, pattern = "Road"),]
slope.road <- slope.road.rec[grepl(x = slope.road.rec$Reference, pattern = "Road"),]
slope.road <- slope.road[!grepl(x = slope.road$reference, pattern = "Cath Fed P 35 3 101 Reference"),]
slope.WP <- total.slope.wide[!grepl(x = total.slope.wide$reclamation, pattern = "Road"),]
slope.WP <- slope.WP[!grepl(x = slope.WP$ART.plot, pattern = "Road"),]
slope.total <- rbind(slope.WP, slope.road)
lf.match <- as.matrix(table(slope.total[9:10]))
slope.road <- slope.road.rec[grepl(x = slope.road.rec$ART.plot, pattern = "Road"),]
slope.road <- slope.road.rec[grepl(x = slope.road.rec$reference, pattern = "Road"),]
slope.road <- slope.road[!grepl(x = slope.road$reference, pattern = "Cath Fed P 35 3 101 Reference"),]
slope.WP <- total.slope.wide[!grepl(x = total.slope.wide$reclamation, pattern = "Road"),]
slope.WP <- slope.WP[!grepl(x = slope.WP$ART.plot, pattern = "Road"),]
slope.total <- rbind(slope.WP, slope.road)
lf.match <- as.matrix(table(slope.total[9:10]))
table(slope.total[9:10])
head(slope.total)
lf.match <- as.matrix(table(slope.total[8:9]))
lf.kappa <- cohen.kappa(lf.match)
ggplotRegression(lm(slope.ref ~ slope.ART, data = total.slope.wide)) +
geom_abline(linetype = "dashed" ) +
xlab("Slope of ART Plots") +
ylab("Slope of Reference Sites") +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 12))
write.csv(total.slope.wide, "C:/Users/sfper/Documents/R/WRFO_git/Topographic")
write.csv(total.slope.wide, "C:/Users/sfper/Documents/R/WRFO_git/Topographic/total.slope.wide.csv")
total.slope.wide <- read.csv("C:/Users/sfper/Documents/R/WRFO_git/Topographic/total.slope.wide.csv")
ggplotRegression <- function(fit){
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red", se = F) +
labs(title = paste("R2 = ",signif(summary(fit)$r.squared, 2),
"Intercept =",signif(fit$coef[[1]],2 ),
" Regression Coefficient =",signif(fit$coef[[2]], 2),
" p-value =",signif(summary(fit)$coef[2,4], 2)))
}
# reference site slope vs ART plot slope # values comes from DEM
ggplotRegression(lm(slope.ref ~ slope.ART, data = total.slope.wide)) +
geom_abline(linetype = "dashed" ) +
xlab("Slope of ART Plots") +
ylab("Slope of Reference Sites") +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 12))
setwd("C:/Users/sfper/Documents/R/WRFO_git")
# pulling raster that has the slope values calculated from DEM in QGIS
slope <- raster("Topographic/Slope08142017.tif")
write.csv(whc.wide, "C:/Users/sfper/Documents/R/WRFO_git/Soil/whc.wide.csv")
library(plotrix)
library(readxl)
library(tidyverse)
library(qdapRegex)
library(ggplot2)
library(Metrics)
setwd("C:/Users/sfper/Documents/R/WRFO_git/Soil/PSA_data.entry")
#### IMPORTING & TIDYING RAW PSA DATA ####
file.list <-list.files(pattern='*.xlsx')
# specifying range of cells to pull in, the excel sheet is NOT tidy
psa.list <- lapply(file.list, read_excel, range = "F12:AQ36")
# removing unneeded columns (all NA or misc info)
psa.list2 <- lapply(psa.list, "[", c(1, 13:16, 22:25, 35:38))
# removing any columns with dates because not all files have date data
# the date column is the only column right now that isn't character
psa.list3 <- lapply(psa.list2, function(x) x[,sapply(x, is.character)])
# column names
psa.names <- c("grav.moist", "tin.wt", "tin.samp.wt", "tin.samp.oven.wt", "subsamp.wt", "site", "plot",
"horizon", "subsamp.oven.wt", "sand", "silt", "clay")
# renaming all columns in the list
psa.list4 <- lapply(psa.list3, setNames, nm = psa.names)
# removing unneeded rows (blank)
psa.clean <- lapply(psa.list4, function(x) x[4:38,])
# collapsing all list dataframes into 1 dataframe
psa.df <- plyr::rbind.fill(psa.clean)
# removing rows that were entirely NA
psa.df.clean <- psa.df[!is.na(psa.df$grav.moist),]
# combining site and plot to create new plot column
# needed to merge with field data
# when plot or site is unknown it will add NA
psa.df.clean$plot <- paste(psa.df.clean$site, psa.df.clean$plot)
# changing all horizon names to lowercase for later merging processes
psa.df.clean$horizon <- tolower(psa.df.clean$horizon)
setwd("C:/Users/sfper/Documents/R/WRFO_git/Soil")
# field data that includes horizon depths
# needed to weight variable percentages
ref.field <- read.csv("ref.soil.field.csv")
art.field <- read.csv("art.soil.field.csv")
art.depth <- read.csv("art.plot.depth.csv")
# adding total pedon depth
art.field <- merge(art.field, art.depth[,c("plot", "Total.Soil.Pedon.Depth")], by = "plot")
# cleaning names so that all rows will merge later
art.field$plot <- gsub(art.field$plot, pattern = "FR|Well Pad", replacement = "")
art.field$plot <- gsub(art.field$plot, pattern = "Federal", replacement = "Fed")
art.field$plot <- rm_white(art.field$plot)
# getting rid of site column
# FIGURE OUT HOW TO REMOVE 1 COLUMN BY NAME
art.field <- art.field[,-2]
soil.ref <- merge(psa.df.clean, ref.field, by = c("plot", "horizon"))
# checking number of plots, should be 11
unique(soil.ref$plot)
# merging ART plot field data with psa data
soil.art <- merge(psa.df.clean, art.field, by = c("plot", "horizon"))
# checking number of plots, should be 28
# right now it should be 26 bc some PSA data had unknown sites or plots, ADD LATER
unique(soil.art$plot)
## changing columns from character to numeric
# columns I want to change
colnames.num <- c("grav.moist", "tin.wt", "tin.samp.wt", "tin.samp.oven.wt", "subsamp.wt", "sand", "silt", "clay")
soil.art[, colnames.num] <- sapply(soil.art[, colnames.num], as.numeric)
soil.ref[, colnames.num] <- sapply(soil.ref[, colnames.num], as.numeric)
# cleaning site names so that they will merge correctly later on
soil.art$site <- gsub(soil.art$site, pattern = "Cath Fed 30 01 Rd",
replacement = "Cath Fed 30 01")
soil.art$site <- gsub(soil.art$site, pattern = "SDC 7326 Rd",
replacement = "SDC 7326")
soil.art$site <- gsub(soil.art$site, pattern = "A-30-3-101S Rd",
replacement = "A-30-3-101S")
soil.ref$site <- gsub(soil.ref$site, pattern = "Fed 30 16",
replacement = "Fed 30-16")
soil.ref[soil.ref$site == "Cath Fed P 35 3 101" &
soil.ref$plot == "Cath Fed P 35 3 101 Road Ref",
"site"] <- "Cath Fed P 35 3 101 Rd"
soil.art$hor.depth <- (soil.art$Lower.Depth - soil.art$Upper.Depth)
# weighting gravimetric moisture (scale 0-1)
# by how much space the horizon took up in the pit
soil.art$hor.grav.wt <- (soil.art$grav.moist * soil.art$hor.depth)/soil.art$Total.Soil.Pedon.Depth
# summing all rock %s from all horizons in each plot
total.whc.art <- aggregate(data = soil.art, hor.grav.wt ~ plot, sum)
### REFERENCE SITES ###
soil.ref$hor.depth <- (soil.ref$Lower.Depth - soil.ref$Upper.Depth)
# weighting gravimetric moisture (scale 0-1)
# by how much space the horizon took up in the pit
soil.ref$hor.grav.wt <- (soil.ref$grav.moist * soil.ref$hor.depth)/
soil.ref$Total.Soil.Pedon.Depth
# summing all rock %s from all horizons in each plot
total.whc.ref <- aggregate(data = soil.ref, hor.grav.wt ~ plot, sum)
### COMBINING ART & REF GRAVIMETRIC ###
# adding site column
# some rows are duplicated which is why I added unique()
total.whc.ref <- unique(merge(total.whc.ref, soil.ref[,c("site", "plot")], by = "plot"))
total.whc.art <- unique(merge(total.whc.art, soil.art[,c("site", "plot")], by = "plot"))
# renaming columns to make less confusing
colnames(total.whc.art) <- c("art.plot", "art.grav.moist", "site")
colnames(total.whc.ref) <- c("ref.site", "ref.grav.moist", "site")
# there should only be 11 unique sites
unique(total.whc.art$site)
unique(total.whc.ref$site)
# merging so that art plots can be compared with their reference
# rows should be equal to the number of rows in total.whc.art
whc.wide <- merge(total.whc.art, total.whc.ref, by = "site")
# removing 3 outliers
whc.wide <- whc.wide[!(whc.wide$art.plot == "Fed 30-16 Plot 2"|
whc.wide$ref.site == "Cath Fed P 35 3 101 Ref"),]
write.csv(whc.wide, "C:/Users/sfper/Documents/R/WRFO_git/Soil/whc.wide.csv")
whc.wide <- read.csv("C:/Users/sfper/Documents/R/WRFO_git/Soil/whc.wide.csv")
# graphing the relationship between ART plots and there reference
# comparing water holding capacity aka gravimetric moisture
# these values were obtained by air drying and then oven drying samples
# for 48 hrs at 105 degrees celsius
ggplotRegression(lm(ref.grav.moist ~ art.grav.moist, data = whc.wide)) +
xlab("ART Gravimetric Moisture ???g") +
ylab("Reference Gravimetric Moisture ???g") +
# geom_abline(linetype = "dashed")
# scale_y_continuous(breaks = c(0.0, 0.02, 0.04, 0.06, 0.08)) +
# scale_x_continuous(breaks = c(0.0, 0.02, 0.04, 0.06, 0.08)) +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 12))
#### LPI DATA BY FUNCTIONAL GROUP ####
setwd("C:/Users/seaperry/Dropbox/DiStefano_WRFO_project")
master.species.list <- as.data.frame(names(summ.cover[6:131]))
write.csv(master.species.list,"master.species.list.csv")
master.species.list <- read.csv("master.species.list.csv")[,c("common.name", "duration", "growth.habit", "invasive")]
master.species.list <- as.data.frame(names(summ.cover[6:131]))
head(master.species.list,3)
head(summ.cover)
# summarizing lpi data based on functional group
summ.ART.fg.cover <- pct.cover(lpi.tall = ART.lpi.point,
tall = FALSE,
hit = "any",
by.year = FALSE,
by.line = FALSE,
duration, growth.habit, invasive
)
# renaming point data
ART.lpi.point <- lpi.tall.layers
# summarizing lpi data based on functional group
summ.ART.fg.cover <- pct.cover(lpi.tall = ART.lpi.point,
tall = FALSE,
hit = "any",
by.year = FALSE,
by.line = FALSE,
duration, growth.habit, invasive
)
